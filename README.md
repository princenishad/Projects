Credit Risk (Default Probabilty Modeling)

With more than 272 variables right from categorical to binary (customer level segmentation has been used to create another 50 categorical, data manipulated and dummy variables)
Using Light GBM as a singleton ensembling model for model creation and for the purpose of implementation we created Stratified K = 5 fold samples of our train dataset.

International Trade Research Paper (Analysing Bilateral Trade Relation between India and China)

Under this research project 2 Linear regression models were created to study the quality and pattern of 
trade taking place between two countries (vis-a-vis other developing economies) from the year 2009 to 2020. 
Moreover econometrics tools such as fixed effects and interaction effects were used to determine country level and category level 
impact on the dependent variable.


Portfolio Optimization with CVaR (Conditional Value at Risk) as Risk factor Creating scenario losses (Convex to Conic Reformulation)


For this project 96 different stocks from NYSE where used to create a optimized portfolio with return scenarios created 
using Multi-variate normalized distribution (Monte-Carlo Simulation) which accounts for Transactional Cost (MILP) , 
Market Impact Cost (optimized using Quadratic Power Cones) and threshold CVaR risk for different delta values (risk coefficient) 
in order to Maximize Utility function (Objective).

Order Book Creation (Order Matching Mechanism)

Using in-build python library such as SortedContainers and the concept of sets, this order matching mechanism processed 93776 orders per second with time per order of 10.66 orders per micro-seconds. 
The main mechanism used for matching was FIFO (First In and First Out). This prototype order matching Framework provided an hindsight experience of storing and handling order-by-order tick data.


Price Point (Valuation based) research on NBFC Stock listed on both BSE and NSE

Under this project 40 NBFC stocks with multiple company f inancial variables where considered for the purpose of company analysis on a financial health factor and 
discovering a price point for each company using a empirical formula which considers both microeconomic and macroeconomic indicators. 
The database to support the research where collected using secondary data sources.


Point (Valuation based) research on Private Banking Stocks listed on both BSE and NSE

Under this project 23 private banking stocks with multiple company financial variables where considered for the purpose of creating new derived variables such as adjusted return to shareholder and flexibility. 
Then a empirical formula was used to estimate a price point for each stock of a private bank.

Regression with a Crab Age Dataset (Kaggle Based Hackathon)

In this competition given 10 distinct feature of a crab, we had to estimate the age for each vector of features. Weighted Least Squares (WLS) econometric model was used to generate a linear regression equation which minimised error residual while handling a data structured problem of heteroscedasticity. 


Mars Spectrometry 2: Gas Chromatography Multi-Label Classification (Driven Data based Hackathon)

In this challenge goal was to detect the presence of certain families of chemical compounds in geological material samples 
using gas chromatography-mass spectrometry (GCMS) data collected for Mars exploration missions.

Flu Shot Learning: Predict H1N1 and Seasonal Flu Vaccines Binary Classification Model (Driven Data based Hackathon)

In this challenge the goal was to predict how likely individuals are to receive their H1N1 and seasonal flu vaccines. 
Specifically, predicting two probabilities: one for h1n1_vaccine and one for seasonal_vaccine.

Intra-Day Return Multi-Classification Model (Trading Directional Signal)

Under this project NSE's 13 Housing NBFC stocks on daily data was analysed following which feature engineering included 
creation of multiple new derived variables based on Joint Probability Density function and 
density clustering Using UMAP (Uniform Manifold Approximate Projection) to predict whether the stock would be Bullish , 
Bearish or Consoliding during the day. The model used was the XGB Classifier.
